{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f053ecdf",
   "metadata": {},
   "source": [
    "# Enterprise Dynamic Parking Pricing Engine\n",
    "Advanced location intelligence with competitive analysis for urban parking optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d660c79",
   "metadata": {},
   "source": [
    "Dependacies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2701fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e305b74a",
   "metadata": {},
   "source": [
    "Load parking data CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75d9e4da",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ruchir\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Ruchir\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Ruchir\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\Ruchir\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Ruchir\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\dataset.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data\\dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019d7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompetitivePosition(Enum):\n",
    "    PRICE_LEADER = \"price_leader\"\n",
    "    COMPETITIVE = \"competitive\" \n",
    "    PREMIUM = \"premium\"\n",
    "    EXPENSIVE = \"expensive\"\n",
    "    ISOLATED = \"isolated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f4bc564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficLevel(Enum):\n",
    "    LOW = \"Low\"\n",
    "    MEDIUM = \"Medium\"\n",
    "    HIGH = \"High\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "555ed0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PricingFactors:\n",
    "    occupancy_weight: float = 1.5\n",
    "    queue_weight: float = 0.8\n",
    "    traffic_weight: float = 0.4\n",
    "    special_day_weight: float = 0.3\n",
    "    vehicle_type_weight: float = 0.2\n",
    "    competitor_weight: float = 0.6\n",
    "    time_of_day_weight: float = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e86796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CompetitorAnalysis:\n",
    "    competitors: Dict[str, Dict[str, float]]\n",
    "    avg_competitor_price: Optional[float]\n",
    "    min_competitor_price: Optional[float]\n",
    "    max_competitor_price: Optional[float]\n",
    "    price_advantage: float\n",
    "    competitive_position: CompetitivePosition\n",
    "    recommendations: List[str]\n",
    "    competitor_count: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3192ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReroutingSuggestion:\n",
    "    space_id: str\n",
    "    price: float\n",
    "    distance_km: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01bd9d",
   "metadata": {},
   "source": [
    " pricing engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1305c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicParkingPricingEngine:\n",
    "    \n",
    "    def __init__(self, base_price: float = 10.0, logger: Optional[logging.Logger] = None):\n",
    "        self.base_price = base_price\n",
    "        self.logger = logger or self._setup_logger()\n",
    "        \n",
    "        # Core data structures\n",
    "        self.historical_patterns: Dict[str, Dict] = {}\n",
    "        self.pricing_history: Dict[str, List[Dict]] = {}\n",
    "        self.distance_matrix: Optional[np.ndarray] = None\n",
    "        self.space_mapping: Dict[str, Dict] = {}\n",
    "        \n",
    "        # Pricing configuration\n",
    "        self.factors = PricingFactors()\n",
    "        self.vehicle_premiums = {'car': 1.0, 'bike': 0.6, 'truck': 1.4}\n",
    "        self.traffic_multipliers = {\n",
    "            TrafficLevel.LOW.value: 0.95,\n",
    "            TrafficLevel.MEDIUM.value: 1.0,\n",
    "            TrafficLevel.HIGH.value: 1.15\n",
    "        }\n",
    "        \n",
    "        # Business constraints\n",
    "        self.MIN_PRICE = 5.0\n",
    "        self.MAX_PRICE = 50.0\n",
    "        self.MAX_PRICE_CHANGE_PCT = 0.15\n",
    "        self.COMPETITOR_RADIUS_KM = 2.0\n",
    "        \n",
    "        self.logger.info(f\"Pricing engine initialized with base price: ${base_price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fac04c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _setup_logger(self) -> logging.Logger:\n",
    "        logger = logging.getLogger('ParkingPricingEngine')\n",
    "        if not logger.handlers:\n",
    "            handler = logging.StreamHandler()\n",
    "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "            handler.setFormatter(formatter)\n",
    "            logger.addHandler(handler)\n",
    "            logger.setLevel(logging.INFO)\n",
    "        return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a1dcca",
   "metadata": {},
   "source": [
    "        Calculate great circle distance between two points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d77de17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _haversine_distance(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "       \n",
    "        R = 6371  # Earth radius in km\n",
    "        \n",
    "        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "        \n",
    "        a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        \n",
    "        return R * c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7fe5f",
   "metadata": {},
   "source": [
    "Build spatial index for competitor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8b327bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_spatial_index(self, df: pd.DataFrame) -> Tuple[np.ndarray, Dict[str, Dict]]:\n",
    "        \n",
    "        required_cols = ['SystemCodeNumber', 'Latitude', 'Longitude']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            raise ValueError(f\"DataFrame missing required columns: {required_cols}\")\n",
    "        \n",
    "        unique_spaces = df[required_cols].drop_duplicates()\n",
    "        n_spaces = len(unique_spaces)\n",
    "        \n",
    "        if n_spaces == 0:\n",
    "            raise ValueError(\"No unique parking spaces found in dataset\")\n",
    "        \n",
    "        distance_matrix = np.zeros((n_spaces, n_spaces))\n",
    "        space_mapping = {}\n",
    "        \n",
    "        for idx, (_, row) in enumerate(unique_spaces.iterrows()):\n",
    "            space_id = str(row['SystemCodeNumber'])\n",
    "            space_mapping[space_id] = {\n",
    "                'index': idx,\n",
    "                'lat': row['Latitude'],\n",
    "                'lon': row['Longitude']\n",
    "            }\n",
    "        \n",
    "                                                                # Vectorized distance calculation\n",
    "        for i, (_, row1) in enumerate(unique_spaces.iterrows()):\n",
    "            for j, (_, row2) in enumerate(unique_spaces.iterrows()):\n",
    "                if i != j:\n",
    "                    distance_matrix[i, j] = self._haversine_distance(\n",
    "                        row1['Latitude'], row1['Longitude'],\n",
    "                        row2['Latitude'], row2['Longitude']\n",
    "                    )\n",
    "        \n",
    "        self.distance_matrix = distance_matrix\n",
    "        self.space_mapping = space_mapping\n",
    "        \n",
    "        self.logger.info(f\"Spatial index built for {n_spaces} parking spaces\")\n",
    "        return distance_matrix, space_mapping\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2e45d",
   "metadata": {},
   "source": [
    "Competitive intelligence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbf9beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def analyze_competitor_landscape(self, space_id: str, current_prices: Dict[str, float]) -> CompetitorAnalysis:\n",
    "        \n",
    "        if not self.space_mapping or space_id not in self.space_mapping:\n",
    "            return CompetitorAnalysis(\n",
    "                competitors={}, avg_competitor_price=None, min_competitor_price=None,\n",
    "                max_competitor_price=None, price_advantage=0,\n",
    "                competitive_position=CompetitivePosition.ISOLATED,\n",
    "                recommendations=[\"No spatial data - premium pricing opportunity\"],\n",
    "                competitor_count=0\n",
    "            )\n",
    "        \n",
    "        space_idx = self.space_mapping[space_id]['index']\n",
    "        competitors = {}\n",
    "        \n",
    "                                                         # Find competitors within radius\n",
    "        for other_space_id, mapping in self.space_mapping.items():\n",
    "            if other_space_id != space_id and other_space_id in current_prices:\n",
    "                other_idx = mapping['index']\n",
    "                distance = self.distance_matrix[space_idx, other_idx]\n",
    "                \n",
    "                if distance <= self.COMPETITOR_RADIUS_KM:\n",
    "                    competitors[other_space_id] = {\n",
    "                        'distance_km': distance,\n",
    "                        'price': current_prices[other_space_id],\n",
    "                        'lat': mapping['lat'],\n",
    "                        'lon': mapping['lon']\n",
    "                    }\n",
    "        \n",
    "        if not competitors:\n",
    "            return CompetitorAnalysis(\n",
    "                competitors={}, avg_competitor_price=None, min_competitor_price=None,\n",
    "                max_competitor_price=None, price_advantage=0,\n",
    "                competitive_position=CompetitivePosition.ISOLATED,\n",
    "                recommendations=[\"No nearby competitors - premium pricing possible\"],\n",
    "                competitor_count=0\n",
    "            )\n",
    "        \n",
    "                                                         # Calculate competitive metrics\n",
    "        competitor_prices = [comp['price'] for comp in competitors.values()]\n",
    "        avg_price = np.mean(competitor_prices)\n",
    "        min_price = min(competitor_prices)\n",
    "        max_price = max(competitor_prices)\n",
    "        \n",
    "        current_price = current_prices.get(space_id, self.base_price)\n",
    "        price_advantage = current_price - avg_price\n",
    "        \n",
    "                                                        # Determine competitive position\n",
    "        if current_price <= min_price:\n",
    "            position = CompetitivePosition.PRICE_LEADER\n",
    "        elif current_price <= avg_price:\n",
    "            position = CompetitivePosition.COMPETITIVE\n",
    "        elif current_price <= max_price:\n",
    "            position = CompetitivePosition.PREMIUM\n",
    "        else:\n",
    "            position = CompetitivePosition.EXPENSIVE\n",
    "        \n",
    "                                                        # Generate strategic recommendations\n",
    "        recommendations = self._generate_pricing_recommendations(position, price_advantage, len(competitors))\n",
    "        \n",
    "        return CompetitorAnalysis(\n",
    "            competitors=competitors,\n",
    "            avg_competitor_price=avg_price,\n",
    "            min_competitor_price=min_price,\n",
    "            max_competitor_price=max_price,\n",
    "            price_advantage=price_advantage,\n",
    "            competitive_position=position,\n",
    "            recommendations=recommendations,\n",
    "            competitor_count=len(competitors)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd79ec4",
   "metadata": {},
   "source": [
    "strategic pricing recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710d0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_pricing_recommendations(self, position: CompetitivePosition, price_advantage: float, competitor_count: int) -> List[str]:\n",
    "        recommendations = []\n",
    "        if position == CompetitivePosition.EXPENSIVE and price_advantage > 5:\n",
    "            recommendations.append(\"Consider price reduction - significantly above market\")\n",
    "        elif position == CompetitivePosition.PRICE_LEADER:\n",
    "            recommendations.append(\"Opportunity for strategic price increase\")\n",
    "        elif competitor_count >= 3 and price_advantage > 2:\n",
    "            recommendations.append(\"Monitor competitor responses to pricing\")\n",
    "        else:\n",
    "            recommendations.append(\"Maintain current competitive positioning\")\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abf1a4",
   "metadata": {},
   "source": [
    "Extract historical demand patterns for predictive pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83b0642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_historical_patterns(self, df: pd.DataFrame) -> Dict[str, Dict]:\n",
    "    required_cols = ['SystemCodeNumber', 'LastUpdatedDate', 'LastUpdatedTime', 'Occupancy', 'Capacity', 'QueueLength', 'TrafficConditionNearby']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "    # Convert datetime with error handling\n",
    "    try:\n",
    "        df['datetime'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'])\n",
    "    except Exception as e:\n",
    "        self.logger.error(f\"Date parsing error: {e}\")\n",
    "        raise ValueError(\"Unable to parse datetime columns\")\n",
    "\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "\n",
    "    patterns = {}\n",
    "\n",
    "    for space_id in df['SystemCodeNumber'].unique():\n",
    "        space_data = df[df['SystemCodeNumber'] == space_id].copy()\n",
    "        if len(space_data) == 0:\n",
    "            continue\n",
    "\n",
    "        # Hourly demand patterns\n",
    "        hourly_occupancy = space_data.groupby('hour')['Occupancy'].agg(['mean', 'std', 'max']).fillna(0)\n",
    "        daily_occupancy = space_data.groupby('day_of_week')['Occupancy'].mean()\n",
    "        queue_patterns = space_data.groupby('hour')['QueueLength'].agg(['mean', 'std', 'max']).fillna(0)\n",
    "        traffic_impact = space_data.groupby('TrafficConditionNearby')['Occupancy'].mean()\n",
    "\n",
    "        capacity = space_data['Capacity'].iloc[0] if len(space_data) > 0 else 1\n",
    "        avg_occupancy_rate = space_data['Occupancy'].mean() / max(capacity, 1)\n",
    "\n",
    "        patterns[str(space_id)] = {\n",
    "            'hourly_occupancy': hourly_occupancy,\n",
    "            'daily_occupancy': daily_occupancy,\n",
    "            'queue_patterns': queue_patterns,\n",
    "            'traffic_impact': traffic_impact,\n",
    "            'capacity': capacity,\n",
    "            'avg_occupancy_rate': avg_occupancy_rate\n",
    "        }\n",
    "\n",
    "    self.historical_patterns = patterns\n",
    "    self.logger.info(f\"Historical patterns extracted for {len(patterns)} spaces\")\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc00b7",
   "metadata": {},
   "source": [
    "Core dynamic pricing algorithm with competitive intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "162858dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dynamic_price(self, space_id: str, current_state: Dict[str, Any], \n",
    "                              current_prices: Optional[Dict[str, float]] = None) -> Tuple[float, List[ReroutingSuggestion]]:\n",
    "        space_id = str(space_id)\n",
    "        \n",
    "               # Validate required state data\n",
    "        required_fields = ['Capacity', 'Occupancy', 'QueueLength', 'TrafficConditionNearby', \n",
    "                          'IsSpecialDay', 'VehicleType', 'LastUpdatedDate', 'LastUpdatedTime']\n",
    "        \n",
    "        missing_fields = [field for field in required_fields if field not in current_state]\n",
    "        if missing_fields:\n",
    "            self.logger.warning(f\"Missing state fields for space {space_id}: {missing_fields}\")\n",
    "            return self.base_price, []\n",
    "        \n",
    "              # Extract state variables\n",
    "        capacity = max(current_state['Capacity'], 1)  # Prevent division by zero\n",
    "        occupancy = max(current_state['Occupancy'], 0)\n",
    "        queue_length = max(current_state['QueueLength'], 0)\n",
    "        traffic_level = current_state['TrafficConditionNearby']\n",
    "        is_special_day = bool(current_state['IsSpecialDay'])\n",
    "        vehicle_type = str(current_state['VehicleType']).lower()\n",
    "        \n",
    "        try:\n",
    "            current_hour = pd.to_datetime(\n",
    "                current_state['LastUpdatedDate'] + ' ' + current_state['LastUpdatedTime']\n",
    "            ).hour\n",
    "        except:\n",
    "            current_hour = datetime.now().hour\n",
    "        \n",
    "                     # Calculate occupancy rate with bounds checking\n",
    "        occupancy_rate = min(occupancy / capacity, 1.0)\n",
    "        \n",
    "                    # 1. Demand-based pricing multipliers\n",
    "        occupancy_multiplier = self._calculate_occupancy_multiplier(occupancy_rate)\n",
    "        queue_multiplier = self._calculate_queue_multiplier(queue_length)\n",
    "        traffic_multiplier = self.traffic_multipliers.get(traffic_level, 1.0)\n",
    "        special_day_multiplier = 1.2 if is_special_day else 1.0\n",
    "        vehicle_multiplier = self.vehicle_premiums.get(vehicle_type, 1.0)\n",
    "        \n",
    "                     # 2. Historical pattern multiplier\n",
    "        time_multiplier = self._calculate_time_multiplier(space_id, current_hour, capacity)\n",
    "        \n",
    "                      \n",
    "                      \n",
    "                       # 3. Competitive pricing intelligence\n",
    "        competitive_multiplier = 1.0\n",
    "        rerouting_suggestions = []\n",
    "        \n",
    "        if current_prices:\n",
    "            comp_analysis = self.analyze_competitor_landscape(space_id, current_prices)\n",
    "            competitive_multiplier, rerouting_suggestions = self._calculate_competitive_strategy(\n",
    "                comp_analysis, occupancy_rate, queue_length\n",
    "            )\n",
    "        \n",
    "                 \n",
    "                 \n",
    "                 # Combine factors with weights\n",
    "        total_weight = sum(vars(self.factors).values())\n",
    "        final_multiplier = (\n",
    "            occupancy_multiplier * self.factors.occupancy_weight +\n",
    "            queue_multiplier * self.factors.queue_weight +\n",
    "            traffic_multiplier * self.factors.traffic_weight +\n",
    "            special_day_multiplier * self.factors.special_day_weight +\n",
    "            vehicle_multiplier * self.factors.vehicle_type_weight +\n",
    "            competitive_multiplier * self.factors.competitor_weight +\n",
    "            time_multiplier * self.factors.time_of_day_weight\n",
    "        ) / total_weight\n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    # Calculate final price with smoothing\n",
    "        new_price = self.base_price * final_multiplier\n",
    "        new_price = self._apply_price_smoothing(space_id, new_price)\n",
    "        new_price = np.clip(new_price, self.MIN_PRICE, self.MAX_PRICE)\n",
    "        new_price = round(new_price, 2)\n",
    "        \n",
    "               \n",
    "               \n",
    "               # Store pricing history\n",
    "        self._record_pricing_decision(space_id, new_price, occupancy_rate, queue_length, {\n",
    "            'occupancy_mult': occupancy_multiplier,\n",
    "            'queue_mult': queue_multiplier,\n",
    "            'traffic_mult': traffic_multiplier,\n",
    "            'special_day_mult': special_day_multiplier,\n",
    "            'vehicle_mult': vehicle_multiplier,\n",
    "            'time_mult': time_multiplier,\n",
    "            'competitive_mult': competitive_multiplier\n",
    "        })\n",
    "        \n",
    "        return new_price, rerouting_suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8740e",
   "metadata": {},
   "source": [
    "Calculate occupancy-based pricing multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63f60954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_occupancy_multiplier(self, occupancy_rate: float) -> float:\n",
    "       \n",
    "        if occupancy_rate >= 0.9:\n",
    "            return 2.0\n",
    "        elif occupancy_rate >= 0.7:\n",
    "            return 1.4 + (occupancy_rate - 0.7) * 3\n",
    "        elif occupancy_rate >= 0.5:\n",
    "            return 1.1 + (occupancy_rate - 0.5) * 1.5\n",
    "        else:\n",
    "            return 0.8 + occupancy_rate * 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4521cda6",
   "metadata": {},
   "source": [
    "Calculate queue-based pricing multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42a62464",
   "metadata": {},
   "outputs": [],
   "source": [
    " def _calculate_queue_multiplier(self, queue_length: int) -> float:\n",
    "\n",
    "        if queue_length > 5:\n",
    "            return 1.3\n",
    "        elif queue_length > 2:\n",
    "            return 1.1\n",
    "        elif queue_length > 0:\n",
    "            return 1.05\n",
    "        else:\n",
    "            return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadcf425",
   "metadata": {},
   "source": [
    "Calculate time-based pricing multiplier from historical patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d212c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_time_multiplier(self, space_id: str, current_hour: int, capacity: int) -> float:\n",
    "    \n",
    "        if space_id not in self.historical_patterns:\n",
    "            return 1.0\n",
    "        \n",
    "        hist_data = self.historical_patterns[space_id]\n",
    "        if current_hour in hist_data['hourly_occupancy'].index:\n",
    "            hist_occupancy_rate = hist_data['hourly_occupancy'].loc[current_hour, 'mean'] / capacity\n",
    "            return 0.9 + hist_occupancy_rate * 0.3\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2334a9b9",
   "metadata": {},
   "source": [
    "Calculate competitive pricing strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f23dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_competitive_strategy(self, comp_analysis: CompetitorAnalysis, \n",
    "                                      occupancy_rate: float, queue_length: int) -> Tuple[float, List[ReroutingSuggestion]]:\n",
    "    \n",
    "        competitive_multiplier = 1.0\n",
    "        rerouting_suggestions = []\n",
    "        \n",
    "        if not comp_analysis.competitors:\n",
    "            return competitive_multiplier, rerouting_suggestions\n",
    "        \n",
    "        \n",
    "        \n",
    "                            # High demand + queue: check for rerouting opportunities\n",
    "        if occupancy_rate >= 0.9 and queue_length > 0:\n",
    "            cheapest_alternatives = sorted(\n",
    "                comp_analysis.competitors.items(),\n",
    "                key=lambda x: x[1]['price']\n",
    "            )[:3]\n",
    "            \n",
    "            for alt_id, alt_data in cheapest_alternatives:\n",
    "                if alt_data['price'] < self.base_price * 1.2:\n",
    "                    rerouting_suggestions.append(ReroutingSuggestion(\n",
    "                        space_id=alt_id,\n",
    "                        price=alt_data['price'],\n",
    "                        distance_km=alt_data['distance_km']\n",
    "                    ))\n",
    "            \n",
    "            competitive_multiplier = 0.95 if comp_analysis.avg_competitor_price < self.base_price else 1.15\n",
    "        \n",
    "        \n",
    "        \n",
    "                           # Low utilization: be more competitive\n",
    "        elif occupancy_rate < 0.5:\n",
    "            if comp_analysis.competitive_position == CompetitivePosition.EXPENSIVE:\n",
    "                competitive_multiplier = 0.85\n",
    "            else:\n",
    "                competitive_multiplier = max(0.9, comp_analysis.min_competitor_price / self.base_price * 0.95)\n",
    "        \n",
    "        \n",
    "        \n",
    "                           \n",
    "                           # Normal occupancy: strategic positioning\n",
    "        else:\n",
    "            position_multipliers = {\n",
    "                CompetitivePosition.EXPENSIVE: 0.95,\n",
    "                CompetitivePosition.PRICE_LEADER: 1.05,\n",
    "                CompetitivePosition.COMPETITIVE: 1.0,\n",
    "                CompetitivePosition.PREMIUM: 1.02\n",
    "            }\n",
    "            competitive_multiplier = position_multipliers.get(comp_analysis.competitive_position, 1.0)\n",
    "        \n",
    "        return competitive_multiplier, rerouting_suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde1db1e",
   "metadata": {},
   "source": [
    "Apply price smoothing to prevent erratic changes,to avoid confussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92115daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_price_smoothing(self, space_id: str, new_price: float) -> float:\n",
    "        if space_id in self.pricing_history and self.pricing_history[space_id]:\n",
    "            last_price = self.pricing_history[space_id][-1]['price']\n",
    "            max_change = last_price * self.MAX_PRICE_CHANGE_PCT\n",
    "            \n",
    "            if abs(new_price - last_price) > max_change:\n",
    "                new_price = last_price + (max_change if new_price > last_price else -max_change)\n",
    "        \n",
    "        return new_price\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f33068",
   "metadata": {},
   "source": [
    "Record pricing decision in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6bfacf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _record_pricing_decision(self, space_id: str, price: float, occupancy_rate: float, \n",
    "                               queue_length: int, factors: Dict[str, float]) -> None:\n",
    "    \n",
    "        if space_id not in self.pricing_history:\n",
    "            self.pricing_history[space_id] = []\n",
    "        \n",
    "        record = {\n",
    "            'timestamp': datetime.now(),\n",
    "            'price': price,\n",
    "            'occupancy_rate': occupancy_rate,\n",
    "            'queue_length': queue_length,\n",
    "            'factors': factors\n",
    "        }\n",
    "        \n",
    "        self.pricing_history[space_id].append(record)\n",
    "        \n",
    "        \n",
    "                # Keep only last 1000 records per space for better performance and memory management\n",
    "        if len(self.pricing_history[space_id]) > 1000:\n",
    "            self.pricing_history[space_id] = self.pricing_history[space_id][-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade43529",
   "metadata": {},
   "source": [
    "Execute real-time pricing simulation with competitive intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51e58fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_real_time_pricing(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "        self.logger.info(\"Starting real-time competitive pricing simulation\")\n",
    "        \n",
    "              # Initialize system\n",
    "        self.extract_historical_patterns(df)\n",
    "        self.build_spatial_index(df)\n",
    "        \n",
    "             # Prepare data\n",
    "        df['datetime'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'])\n",
    "        df_sorted = df.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "            # Simulation data structures\n",
    "        current_prices = {}\n",
    "        simulation_results = []\n",
    "        rerouting_events = []\n",
    "        competitive_insights = []\n",
    "        \n",
    "        self.logger.info(f\"Processing {len(df_sorted)} records across {df_sorted['SystemCodeNumber'].nunique()} spaces\")\n",
    "        \n",
    "             # Process by timestamp batches\n",
    "        for timestamp, batch_df in df_sorted.groupby('datetime'):\n",
    "            for _, row in batch_df.iterrows():\n",
    "                space_id = str(row['SystemCodeNumber'])\n",
    "                current_state = row.to_dict()\n",
    "                \n",
    "                # Calculate dynamic price\n",
    "                new_price, rerouting_suggestions = self.calculate_dynamic_price(\n",
    "                    space_id, current_state, current_prices\n",
    "                )\n",
    "                current_prices[space_id] = new_price\n",
    "                \n",
    "                # Store results\n",
    "                simulation_results.append({\n",
    "                    'timestamp': timestamp,\n",
    "                    'space_id': space_id,\n",
    "                    'price': new_price,\n",
    "                    'occupancy': row['Occupancy'],\n",
    "                    'capacity': row['Capacity'],\n",
    "                    'occupancy_rate': row['Occupancy'] / max(row['Capacity'], 1),\n",
    "                    'queue_length': row['QueueLength'],\n",
    "                    'traffic_condition': row['TrafficConditionNearby'],\n",
    "                    'vehicle_type': row['VehicleType'],\n",
    "                    'is_special_day': row['IsSpecialDay']\n",
    "                })\n",
    "                \n",
    "                # Handle rerouting events\n",
    "                if rerouting_suggestions and row['Occupancy'] >= row['Capacity'] * 0.9:\n",
    "                    for suggestion in rerouting_suggestions:\n",
    "                        rerouting_events.append({\n",
    "                            'timestamp': timestamp,\n",
    "                            'from_space': space_id,\n",
    "                            'from_price': new_price,\n",
    "                            'to_space': suggestion.space_id,\n",
    "                            'to_price': suggestion.price,\n",
    "                            'distance_km': suggestion.distance_km,\n",
    "                            'savings': new_price - suggestion.price\n",
    "                        })\n",
    "                \n",
    "                # Competitive analysis\n",
    "                if current_prices and len(current_prices) > 1:\n",
    "                    comp_analysis = self.analyze_competitor_landscape(space_id, current_prices)\n",
    "                    if comp_analysis.competitors:\n",
    "                        competitive_insights.append({\n",
    "                            'timestamp': timestamp,\n",
    "                            'space_id': space_id,\n",
    "                            'price': new_price,\n",
    "                            'competitive_position': comp_analysis.competitive_position.value,\n",
    "                            'price_advantage': comp_analysis.price_advantage,\n",
    "                            'competitor_count': comp_analysis.competitor_count,\n",
    "                            'avg_competitor_price': comp_analysis.avg_competitor_price\n",
    "                        })\n",
    "        \n",
    "        # Convert to DataFrames\n",
    "        results_df = pd.DataFrame(simulation_results)\n",
    "        rerouting_df = pd.DataFrame(rerouting_events)\n",
    "        competitive_df = pd.DataFrame(competitive_insights)\n",
    "        \n",
    "        self.logger.info(f\"Simulation complete: {len(results_df)} pricing decisions, \"\n",
    "                        f\"{len(rerouting_df)} rerouting events, {len(competitive_df)} competitive analyses\")\n",
    "        \n",
    "        return results_df, rerouting_df, competitive_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b8e9c4",
   "metadata": {},
   "source": [
    "Generate comprehensive business analytics report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b9f0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_business_analytics_report(self, results_df: pd.DataFrame, \n",
    "                                         rerouting_df: Optional[pd.DataFrame] = None,\n",
    "                                         competitive_df: Optional[pd.DataFrame] = None) -> Dict[str, Any]:\n",
    "        \n",
    "        \n",
    "        if results_df.empty:\n",
    "            self.logger.warning(\"Empty results DataFrame provided\")\n",
    "            return {}\n",
    "        \n",
    "        report = {}\n",
    "        \n",
    "                  # Pricing performance metrics\n",
    "        report['pricing_performance'] = {\n",
    "            'avg_price': results_df['price'].mean(),\n",
    "            'price_range': (results_df['price'].min(), results_df['price'].max()),\n",
    "            'price_volatility': results_df['price'].std(),\n",
    "            'price_stability_index': 1 - (results_df['price'].std() / results_df['price'].mean())\n",
    "        }\n",
    "        \n",
    "                      # Utilization metrics\n",
    "        avg_occupancy_rate = results_df['occupancy_rate'].mean()\n",
    "        report['utilization_metrics'] = {\n",
    "            'avg_occupancy_rate': avg_occupancy_rate,\n",
    "            'peak_occupancy_rate': results_df['occupancy_rate'].max(),\n",
    "            'avg_queue_length': results_df['queue_length'].mean(),\n",
    "            'high_demand_instances': (results_df['occupancy_rate'] > 0.8).sum()\n",
    "        }\n",
    "        \n",
    "                  \n",
    "                  \n",
    "                  # Revenue optimization\n",
    "        total_capacity_hours = results_df['capacity'].sum()\n",
    "        total_occupied_hours = results_df['occupancy'].sum()\n",
    "        estimated_revenue = (results_df['occupancy'] * results_df['price']).sum()\n",
    "        \n",
    "        report['revenue_optimization'] = {\n",
    "            'estimated_total_revenue': estimated_revenue,\n",
    "            'revenue_per_occupied_hour': estimated_revenue / max(total_occupied_hours, 1),\n",
    "            'capacity_utilization': total_occupied_hours / max(total_capacity_hours, 1),\n",
    "            'revenue_efficiency_score': estimated_revenue / (total_capacity_hours * self.base_price)\n",
    "        }\n",
    "        \n",
    "                  \n",
    "                  \n",
    "                   # Competitive intelligence\n",
    "        if competitive_df is not None and not competitive_df.empty:\n",
    "            position_dist = competitive_df['competitive_position'].value_counts()\n",
    "            report['competitive_intelligence'] = {\n",
    "                'position_distribution': position_dist.to_dict(),\n",
    "                'avg_price_advantage': competitive_df['price_advantage'].mean(),\n",
    "                'competitive_pressure_events': (competitive_df['price_advantage'] < -2).sum(),\n",
    "                'avg_nearby_competitors': competitive_df['competitor_count'].mean()\n",
    "            }\n",
    "        \n",
    "                \n",
    "                \n",
    "                \n",
    "                 # Rerouting intelligence\n",
    "        if rerouting_df is not None and not rerouting_df.empty:\n",
    "            report['rerouting_intelligence'] = {\n",
    "                'total_suggestions': len(rerouting_df),\n",
    "                'avg_customer_savings': rerouting_df['savings'].mean(),\n",
    "                'avg_rerouting_distance': rerouting_df['distance_km'].mean()\n",
    "            }\n",
    "        \n",
    "      \n",
    "      \n",
    "      \n",
    "                    # Space performance analysis\n",
    "        space_perf = results_df.groupby('space_id').agg({\n",
    "            'price': ['mean', 'std'],\n",
    "            'occupancy_rate': ['mean', 'max'],\n",
    "            'occupancy': 'sum',\n",
    "            'queue_length': 'mean'\n",
    "        })\n",
    "        \n",
    "        space_perf['revenue_score'] = (\n",
    "            space_perf[('occupancy', 'sum')] * space_perf[('price', 'mean')]\n",
    "        )\n",
    "        \n",
    "        report['space_performance'] = space_perf.sort_values('revenue_score', ascending=False).to_dict()\n",
    "        \n",
    "                  \n",
    "                  \n",
    "                  \n",
    "                   # Strategic recommendations\n",
    "        report['recommendations'] = self._generate_strategic_recommendations(\n",
    "            results_df, competitive_df, rerouting_df\n",
    "        )\n",
    "        \n",
    "        self.logger.info(\"Business analytics report generated successfully\")\n",
    "        return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f871a",
   "metadata": {},
   "source": [
    "Generate strategic business recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96752f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_strategic_recommendations(self, results_df: pd.DataFrame,\n",
    "                                          competitive_df: Optional[pd.DataFrame],\n",
    "                                          rerouting_df: Optional[pd.DataFrame]) -> List[str]:\n",
    "    \n",
    "        recommendations = []\n",
    "        \n",
    "        # Utilization-based recommendations\n",
    "        space_perf = results_df.groupby('space_id')['occupancy_rate'].mean()\n",
    "        low_util_spaces = (space_perf < 0.4).sum()\n",
    "        if low_util_spaces > 0:\n",
    "            recommendations.append(f\"Implement promotional pricing for {low_util_spaces} underutilized spaces\")\n",
    "        \n",
    "        # Competitive positioning\n",
    "        if competitive_df is not None and not competitive_df.empty:\n",
    "            expensive_ratio = (competitive_df['competitive_position'] == 'expensive').sum() / len(competitive_df)\n",
    "            if expensive_ratio > 0.2:\n",
    "                recommendations.append(\"Review pricing strategy - high proportion of expensive positioning\")\n",
    "        \n",
    "        # Queue management\n",
    "        high_queue_ratio = (results_df['queue_length'] > 2).sum() / len(results_df)\n",
    "        if high_queue_ratio > 0.1:\n",
    "            recommendations.append(\"Implement surge pricing for frequently congested spaces\")\n",
    "        \n",
    "        # Rerouting optimization\n",
    "        if rerouting_df is not None and not rerouting_df.empty:\n",
    "            avg_savings = rerouting_df['savings'].mean()\n",
    "            if avg_savings > 2:\n",
    "                recommendations.append(f\"Enhance rerouting system - ${avg_savings:.2f} average savings available\")\n",
    "        \n",
    "        if not recommendations:\n",
    "            recommendations = [\n",
    "                \"Continue monitoring competitive landscape\",\n",
    "                \"Implement dynamic surge pricing during peak periods\",\n",
    "                \"Consider loyalty programs for frequent users\"\n",
    "            ]\n",
    "        \n",
    "        return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2419d9",
   "metadata": {},
   "source": [
    "Initialize enterprise parking pricing engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e01b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_pricing_engine(base_price: float = 10.0) -> DynamicParkingPricingEngine:\n",
    "    \n",
    "    logger = logging.getLogger('ParkingPricingSystem')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    engine = DynamicParkingPricingEngine(base_price=base_price, logger=logger)\n",
    "    logger.info(f\"Enterprise pricing engine initialized with base price: ${base_price}\")\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c4057",
   "metadata": {},
   "source": [
    "Analytics module for pricing performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a626143",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PricingAnalytics:\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_price_elasticity(results_df: pd.DataFrame) -> Dict[str, float]:\n",
    "        #Calculate price elasticity of demand by space\n",
    "        elasticity_metrics = {}\n",
    "        \n",
    "        for space_id in results_df['space_id'].unique():\n",
    "            space_data = results_df[results_df['space_id'] == space_id].copy()\n",
    "            \n",
    "            if len(space_data) < 10:  # Need sufficient data points\n",
    "                continue\n",
    "                \n",
    "            # Calculate price changes and occupancy changes\n",
    "            space_data = space_data.sort_values('timestamp')\n",
    "            space_data['price_change'] = space_data['price'].pct_change()\n",
    "            space_data['occupancy_change'] = space_data['occupancy_rate'].pct_change()\n",
    "            \n",
    "            # Filter out extreme values and zeros\n",
    "            valid_data = space_data[\n",
    "                (abs(space_data['price_change']) < 0.3) & \n",
    "                (abs(space_data['occupancy_change']) < 0.5) &\n",
    "                (space_data['price_change'] != 0)\n",
    "            ]\n",
    "            \n",
    "            if len(valid_data) >= 5:\n",
    "                try:\n",
    "                    # Price elasticity = % change in quantity / % change in price\n",
    "                    elasticity = (valid_data['occupancy_change'] / valid_data['price_change']).mean()\n",
    "                    elasticity_metrics[space_id] = elasticity\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        return elasticity_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d1a195",
   "metadata": {},
   "source": [
    "Identify revenue optimization opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbd986",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3890460531.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[33], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    def analyze_revenue_optimization_opportunities(results_df: pd.DataFrame,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "@staticmethod\n",
    "def analyze_revenue_optimization_opportunities(results_df: pd.DataFrame, \n",
    "                                                 competitive_df: Optional[pd.DataFrame] = None) -> Dict[str, Any]:\n",
    "    \n",
    "        opportunities = {}\n",
    "        \n",
    "        # Underpriced spaces with high demand\n",
    "        high_demand_low_price = results_df[\n",
    "            (results_df['occupancy_rate'] > 0.8) & \n",
    "            (results_df['price'] < results_df['price'].quantile(0.3))\n",
    "        ]\n",
    "        \n",
    "        if not high_demand_low_price.empty:\n",
    "            opportunities['underpriced_high_demand'] = {\n",
    "                'space_count': high_demand_low_price['space_id'].nunique(),\n",
    "                'avg_occupancy': high_demand_low_price['occupancy_rate'].mean(),\n",
    "                'avg_price': high_demand_low_price['price'].mean(),\n",
    "                'revenue_potential': high_demand_low_price['occupancy'].sum() * \n",
    "                                   (results_df['price'].median() - high_demand_low_price['price'].mean())\n",
    "            }\n",
    "        \n",
    "        # Overpriced spaces with low demand\n",
    "        low_demand_high_price = results_df[\n",
    "            (results_df['occupancy_rate'] < 0.4) & \n",
    "            (results_df['price'] > results_df['price'].quantile(0.7))\n",
    "        ]\n",
    "        \n",
    "        if not low_demand_high_price.empty:\n",
    "            opportunities['overpriced_low_demand'] = {\n",
    "                'space_count': low_demand_high_price['space_id'].nunique(),\n",
    "                'avg_occupancy': low_demand_high_price['occupancy_rate'].mean(),\n",
    "                'avg_price': low_demand_high_price['price'].mean(),\n",
    "                'utilization_improvement_potential': (0.6 - low_demand_high_price['occupancy_rate'].mean()) * 100\n",
    "            }\n",
    "        \n",
    "        # Competitive pricing gaps\n",
    "        if competitive_df is not None and not competitive_df.empty:\n",
    "            significant_gaps = competitive_df[abs(competitive_df['price_advantage']) > 3]\n",
    "            if not significant_gaps.empty:\n",
    "                opportunities['competitive_gaps'] = {\n",
    "                    'space_count': significant_gaps['space_id'].nunique(),\n",
    "                    'avg_price_gap': significant_gaps['price_advantage'].mean(),\n",
    "                    'repositioning_required': (significant_gaps['price_advantage'] > 3).sum()\n",
    "                }\n",
    "        \n",
    "        return opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854aa27d",
   "metadata": {},
   "source": [
    "Basic demand forecast using historical patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e17065b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1360050488.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    def generate_demand_forecast(results_df: pd.DataFrame, forecast_hours: int = 24) -> pd.DataFrame:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "@staticmethod\n",
    "    def generate_demand_forecast(results_df: pd.DataFrame, forecast_hours: int = 24) -> pd.DataFrame:\n",
    "    \n",
    "        forecast_data = []\n",
    "        \n",
    "        # Extract hourly patterns\n",
    "        results_df['hour'] = pd.to_datetime(results_df['timestamp']).dt.hour\n",
    "        hourly_patterns = results_df.groupby(['space_id', 'hour']).agg({\n",
    "            'occupancy_rate': ['mean', 'std'],\n",
    "            'price': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Generate forecast\n",
    "        base_time = pd.to_datetime(results_df['timestamp'].max())\n",
    "        \n",
    "        for space_id in results_df['space_id'].unique():\n",
    "            space_patterns = hourly_patterns[hourly_patterns['space_id'] == space_id]\n",
    "            \n",
    "            for h in range(forecast_hours):\n",
    "                forecast_time = base_time + timedelta(hours=h+1)\n",
    "                hour = forecast_time.hour\n",
    "                \n",
    "                # Find historical pattern for this hour\n",
    "                hour_pattern = space_patterns[space_patterns['hour'] == hour]\n",
    "                \n",
    "                if not hour_pattern.empty:\n",
    "                    predicted_occupancy = hour_pattern[('occupancy_rate', 'mean')].iloc[0]\n",
    "                    occupancy_std = hour_pattern[('occupancy_rate', 'std')].iloc[0]\n",
    "                    suggested_price = hour_pattern[('price', 'mean')].iloc[0]\n",
    "                else:\n",
    "                    # Use daily average if no pattern found\n",
    "                    space_data = results_df[results_df['space_id'] == space_id]\n",
    "                    predicted_occupancy = space_data['occupancy_rate'].mean()\n",
    "                    occupancy_std = space_data['occupancy_rate'].std()\n",
    "                    suggested_price = space_data['price'].mean()\n",
    "                \n",
    "                forecast_data.append({\n",
    "                    'space_id': space_id,\n",
    "                    'forecast_time': forecast_time,\n",
    "                    'predicted_occupancy_rate': predicted_occupancy,\n",
    "                    'confidence_interval': occupancy_std,\n",
    "                    'suggested_price': suggested_price\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(forecast_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad606eb",
   "metadata": {},
   "source": [
    "Report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23edcaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportGenerator:\n",
    "   \n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_executive_summary(report_data: Dict[str, Any]) -> str:\n",
    "        # executive summary \n",
    "        \n",
    "        summary = []\n",
    "        summary.append(\"EXECUTIVE SUMMARY - DYNAMIC PARKING PRICING ANALYTICS\")\n",
    "        summary.append(\"=\" * 60)\n",
    "        \n",
    "        # Key performance indicators\n",
    "        pricing_perf = report_data.get('pricing_performance', {})\n",
    "        revenue_opt = report_data.get('revenue_optimization', {})\n",
    "        util_metrics = report_data.get('utilization_metrics', {})\n",
    "        \n",
    "        summary.append(f\"\\nKEY PERFORMANCE INDICATORS:\")\n",
    "        summary.append(f\"• Average Parking Price: ${pricing_perf.get('avg_price', 0):.2f}\")\n",
    "        summary.append(f\"• Revenue Efficiency: {revenue_opt.get('revenue_efficiency_score', 0):.1%}\")\n",
    "        summary.append(f\"• Capacity Utilization: {util_metrics.get('avg_occupancy_rate', 0):.1%}\")\n",
    "        summary.append(f\"• Price Stability Index: {pricing_perf.get('price_stability_index', 0):.1%}\")\n",
    "        \n",
    "        # Competitive positioning\n",
    "        comp_intel = report_data.get('competitive_intelligence', {})\n",
    "        if comp_intel:\n",
    "            summary.append(f\"\\nCOMPETITIVE POSITIONING:\")\n",
    "            summary.append(f\"• Average Price Advantage: ${comp_intel.get('avg_price_advantage', 0):.2f}\")\n",
    "            summary.append(f\"• Competitive Pressure Events: {comp_intel.get('competitive_pressure_events', 0):,}\")\n",
    "        \n",
    "        # Strategic priorities\n",
    "        recommendations = report_data.get('recommendations', [])\n",
    "        if recommendations:\n",
    "            summary.append(f\"\\nSTRATEGIC PRIORITIES:\")\n",
    "            for i, rec in enumerate(recommendations[:3], 1):\n",
    "                summary.append(f\"• {rec}\")\n",
    "        \n",
    "        return \"\\n\".join(summary)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ba42b",
   "metadata": {},
   "source": [
    "Exporting analysis results to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07203ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "    def export_to_csv(results_df: pd.DataFrame, competitive_df: Optional[pd.DataFrame] = None,\n",
    "                     rerouting_df: Optional[pd.DataFrame] = None, filename_prefix: str = \"parking_analytics\") -> List[str]:\n",
    "        \n",
    "        \n",
    "        exported_files = []\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Main results\n",
    "        results_filename = f\"{filename_prefix}_results_{timestamp}.csv\"\n",
    "        results_df.to_csv(results_filename, index=False)\n",
    "        exported_files.append(results_filename)\n",
    "        \n",
    "        # Competitive analysis\n",
    "        if competitive_df is not None and not competitive_df.empty:\n",
    "            comp_filename = f\"{filename_prefix}_competitive_{timestamp}.csv\"\n",
    "            competitive_df.to_csv(comp_filename, index=False)\n",
    "            exported_files.append(comp_filename)\n",
    "        \n",
    "        # Rerouting events\n",
    "        if rerouting_df is not None and not rerouting_df.empty:\n",
    "            rerouting_filename = f\"{filename_prefix}_rerouting_{timestamp}.csv\"\n",
    "            rerouting_df.to_csv(rerouting_filename, index=False)\n",
    "            exported_files.append(rerouting_filename)\n",
    "        \n",
    "        return exported_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10cca67",
   "metadata": {},
   "source": [
    "Function executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    \n",
    "    # Initialize engine\n",
    "    engine = initialize_pricing_engine(base_price=12.0)\n",
    "    \n",
    "    print(\"DYNAMIC PARKING PRICING SYSTEM\")\n",
    "    print(\" Analytics & Competitive Intelligence Platform\")\n",
    "    print(\"\\nSYSTEM CAPABILITIES:\")\n",
    "    print(\"✓ Real-time competitive price monitoring\")\n",
    "    print(\"✓ Geographic proximity analysis (Haversine formula)\")\n",
    "    print(\"✓ Intelligent customer rerouting for capacity optimization\")\n",
    "    print(\"✓ Historical demand pattern recognition\")\n",
    "    print(\"✓ Revenue optimization with price elasticity analysis\")\n",
    "    print(\"✓ Executive reporting and business intelligence\")\n",
    "    \n",
    "    print(f\"\\nTo run analysis:\")\n",
    "    print(f\"  df = pd.read_csv('parking_data.csv')\")\n",
    "    print(f\"  results, rerouting, competitive = engine.simulate_real_time_pricing(df)\")\n",
    "    print(f\"  report = engine.generate_business_analytics_report(results, rerouting, competitive)\")\n",
    "    print(f\"  summary = ReportGenerator.generate_executive_summary(report)\")\n",
    "    \n",
    "    return engine\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pricing_engine = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
